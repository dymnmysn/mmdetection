{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmdet.structures.mask.structures import BitmapMasks\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_instance_mask_labels = torch.load('gt_instance_mask_labels.pt',map_location=torch.device('cpu'))\n",
    "gt_instance_masks = torch.load('gt_instance_masks.pt',map_location=torch.device('cpu'))\n",
    "seg_fields = torch.load('seg_fields.pt',map_location=torch.device('cpu'))\n",
    "seg_preds = torch.load('seg_preds.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gt_instance_mask_labels\n",
    "masks = gt_instance_masks\n",
    "fields = seg_fields\n",
    "preds = seg_preds\n",
    "thinglabels={2,3,4,5,8,9,10,11}\n",
    "tmasks = [mask.to_tensor(dtype=torch.float32, device='cpu') for mask in masks]\n",
    "nmasks = [mask.to_ndarray() for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tensor(tensor):\n",
    "    # Convert the PyTorch tensor to a NumPy array\n",
    "    array = tensor.numpy()\n",
    "\n",
    "    # Display the array using Matplotlib\n",
    "    plt.imshow(array, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_array(array):\n",
    "    plt.imshow(array, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_as_png(array, file_path):\n",
    "    # Normalize the array to 0-255\n",
    "    normalized_array = (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "    scaled_array = (normalized_array * 255).astype(np.uint8)\n",
    "\n",
    "    # Create PIL Image from the array\n",
    "    image = Image.fromarray(scaled_array)\n",
    "\n",
    "    # Save the image as PNG\n",
    "    image.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcenterfield(mask):\n",
    "    # Calculate the bounding box around the mask\n",
    "    positive_indices = np.where(mask)\n",
    "    min_row, min_col = np.min(positive_indices, axis=1)\n",
    "    max_row, max_col = np.max(positive_indices, axis=1)\n",
    "    center = ((min_col + max_col) // 2, (min_row + max_row) // 2)\n",
    "    width = max_col - min_col + 1\n",
    "    height = max_row - min_row + 1\n",
    "\n",
    "    # Generate the Gaussian kernel\n",
    "    deviation = (width /3, height / 3)\n",
    "    def generate_2d_gaussian_kernel(shape, center, deviation):\n",
    "        x, y = np.indices(shape)\n",
    "        y_center, x_center = center\n",
    "        exponent = -((x - x_center)**2 / (2 * deviation[1]**2) + (y - y_center)**2 / (2 * deviation[0]**2))\n",
    "        gaussian_kernel = np.exp(exponent)\n",
    "        return gaussian_kernel\n",
    "    kernel = generate_2d_gaussian_kernel(mask.shape, center, deviation)\n",
    "    filtered_mask = kernel * mask\n",
    "    return filtered_mask\n",
    "\n",
    "def getdistancefield(mask):\n",
    "    # Find the indices of positive elements in the mask\n",
    "    positive_indices = np.where(mask)\n",
    "\n",
    "    # Calculate the bounding box around the positive elements\n",
    "    min_row, min_col = np.min(positive_indices, axis=1)\n",
    "    max_row, max_col = np.max(positive_indices, axis=1)\n",
    "\n",
    "    # Calculate the center point of the bounding box\n",
    "    center_row = (min_row + max_row) // 2\n",
    "    center_col = (min_col + max_col) // 2\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    width = max_col - min_col + 1\n",
    "    height = max_row - min_row + 1\n",
    "\n",
    "    # Calculate the coordinates of each pixel in the image\n",
    "    rows, cols = np.indices(mask.shape[:2])\n",
    "\n",
    "    # Calculate the distances between each pixel and the center point\n",
    "    distances_x = (cols - center_col) / (width - 1)\n",
    "    distances_y = (rows - center_row) / (height - 1)\n",
    "\n",
    "    # Stack the distances along the channel axis\n",
    "    distances = np.stack((distances_x, distances_y), axis=-1)\n",
    "    masked_tensor = distances * mask[..., None]\n",
    "    return masked_tensor\n",
    "\n",
    "def getfields(mask):\n",
    "    distancefield = getdistancefield(mask)\n",
    "    centerfield = getcenterfield(mask)\n",
    "    return np.concatenate((distancefield, centerfield[..., None]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_getfields(batched_masks):\n",
    "    batch_fields = []\n",
    "    for masks in batched_masks:\n",
    "        fields = getfields(masks[0])\n",
    "        for mask in masks[1:]:\n",
    "            fields += getfields(mask)\n",
    "        batch_fields.append(fields)\n",
    "    return batch_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_getfields_classwise(bitmap_batch,tensorlabels):\n",
    "    batched_masks = [mask.to_ndarray() for mask in bitmap_batch]\n",
    "    labels = [label.numpy() for label in tensorlabels]\n",
    "    batch_fields = []\n",
    "    out_tensors = []\n",
    "    for labels,masks in zip(labels,batched_masks):\n",
    "        dummy = getfields(masks[0])*0\n",
    "        fields = {i:torch.from_numpy(dummy.copy()) for i in thinglabels}\n",
    "        for label,mask in zip(labels,masks):\n",
    "            fields[int(label)] += torch.from_numpy(getfields(mask))\n",
    "        batch_fields.append(fields)\n",
    "        out_tensors.append(torch.cat(tuple(fields.values()),dim = -1).permute([2,0,1]))\n",
    "    return batch_fields,torch.stack(out_tensors,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "allm,allt = batch_getfields_classwise(masks,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 24, 160, 336])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_fields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rgb_array(array):\n",
    "    # Visualize each channel separately\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    for i in range(3):\n",
    "        im = axes[i].imshow(array[..., i], cmap='gray')\n",
    "        axes[i].set_title(f'Channel {i+1}')\n",
    "        fig.colorbar(im, ax=axes[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_rgb_array(allt[0][2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPIED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bura benden\n",
    "        # Device degistir oyle dene sorun cozulmedi\n",
    "        \"\"\"\n",
    "        c = 0\n",
    "        vs = []\n",
    "        for bgm in gt_masks:\n",
    "            bb = bgm.get_bboxes()\n",
    "            #vfh = torch.tensor(bgm[0].masks[0],dtype=torch.float32, device=gt_bboxes[0].device)\n",
    "            #vfw = torch.tensor(bgm[0].masks[0],dtype=torch.float32, device=gt_bboxes[0].device)\n",
    "            vfh = torch.zeros(bgm[0].masks[0].shape,dtype=torch.float32, device='cpu')\n",
    "            vfw = torch.zeros(bgm[0].masks[0].shape,dtype=torch.float32, device='cpu')\n",
    "            for i,gm in enumerate(bgm):\n",
    "                bbox = bb[i]\n",
    "                cbbw = (bbox[0]+bbox[2])/2\n",
    "                cbbh = (bbox[1]+bbox[3])/2\n",
    "                w = bbox[2] - bbox[0]\n",
    "                h = bbox[3] - bbox[1]\n",
    "                #m = torch.tensor(gm,dtype=torch.float32, device=gt_bboxes[0].device)\n",
    "                m = torch.tensor(gm,dtype=torch.float32, device='cpu')\n",
    "                vh = m.clone()\n",
    "                vw = m.clone()\n",
    "                for ih in range(m.shape[0]):\n",
    "                    for iw in range(m.shape[1]):\n",
    "                        if m[ih][iw]:\n",
    "                            #vh[ih][iw] = (ih - cbbh)/h\n",
    "                            #vw[ih][iw] = (iw - cbbw)/w\n",
    "                            vh[ih][iw] = (ih - cbbh)\n",
    "                            vw[ih][iw] = (iw - cbbw)\n",
    "                vfh.add_(vh)\n",
    "                vfw.add_(vw)\n",
    "            vs.append([vfh,vfw])\n",
    "        vs\n",
    "        from debug import yukle,yuklemask,gor2d,gor2dabs\n",
    "        from mmcv.visualization import imshow_bboxes\n",
    "        yukle(img)\n",
    "        yuklemask(gt_masks)\n",
    "        imshow_bboxes('sil.png',gt_bboxes[0].cpu().numpy(), out_file='sil2.png', show=False)\n",
    "        gor2d(vs[0][0])\n",
    "        gor2dabs(vs[0][0])\n",
    "        \"\"\"\n",
    "\n",
    "        gt_semantic_segs = torch.stack(gt_semantic_segs)\n",
    "        if self.seg_rescale_factor != 1.0:\n",
    "            gt_semantic_segs = F.interpolate(\n",
    "                gt_semantic_segs.float(),\n",
    "                scale_factor=self.seg_rescale_factor,\n",
    "                mode='nearest').squeeze(1)\n",
    "\n",
    "        # Things classes will be merged to one class in PanopticFPN.\n",
    "        gt_semantic_segs = self._set_things_to_void(gt_semantic_segs)\n",
    "\n",
    "        if seg_preds.shape[-2:] != gt_semantic_segs.shape[-2:]:\n",
    "            seg_preds = interpolate_as(seg_preds, gt_semantic_segs)\n",
    "        seg_preds = seg_preds.permute((0, 2, 3, 1))\n",
    "\n",
    "        loss_seg = self.loss_seg(\n",
    "            seg_preds.reshape(-1, self.num_classes),  # => [NxHxW, C]\n",
    "            gt_semantic_segs.reshape(-1).long())\n",
    "\n",
    "        return dict(loss_seg=loss_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panwaymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
